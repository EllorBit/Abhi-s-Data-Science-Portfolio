{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div>\n<a href=\"#\" style=\"font-size:48px;font-weight:600;margin-bottom:20px;\"> Numpy, Scipy and Pandas for Dummy Data Scientists </a>\n<div style=\"padding-top: 20px;\"><p style=\"font-size:24px;\">Numpy, Scipy and pandas library basics with code example and brief description</p></div>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"<div>\n<a href=\"#\" style=\"font-size:48px;font-weight:600;margin-bottom:20px;\"> Numpy </a>\n<div style=\"padding-top: 20px;\"><p style=\"font-size:24px;\">Numpy library basics with code example</p></div>\n</div>\n"},{"metadata":{},"cell_type":"markdown","source":"## **N-Dimensional array**\n> Arrays allows you to perform mathematical operations on whole blocks of data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# easiest way to create an array is by using an array function\nimport numpy as np # I am importing numpy as np\n\nscores = [89,56.34, 76,89, 98]\nfirst_arr =np.array(scores)\nprint(first_arr)\nprint(first_arr.dtype)  # .dtype return the data type of the array object","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nested lists with equal length, will be converted into a multidimensional array\nscores_1 = [[34,56,23,89], [11,45,76,34]]\nsecond_arr = np.array(scores_1)\nprint(second_arr)\nprint(second_arr.ndim)  #.ndim gives you the dimensions of an array.\nprint(second_arr.shape) #(number of rows, number of columns)\nprint(second_arr.dtype) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.zeros(10) # returns a array of zeros, the same applies for np.ones(10)\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.ones(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.zeros((4,3)) # you can also mention the shape of the array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.arange(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.eye(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Batch operations on data can be performed without using for loops, this is called vectorization\nscores = [89,56.34, 76,89, 98]\nfirst_arr =np.array(scores)\nprint(first_arr)\nprint(first_arr * first_arr)\nprint(first_arr - first_arr)\nprint(1/(first_arr))\nprint(first_arr ** 0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Indexing and Slicing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# you may want to select a subset of your data, for which Numpy array indexing is really useful\nnew_arr = np.arange(12)\nprint(new_arr)\nprint(new_arr[5])\nprint(new_arr[4:9])\nnew_arr[4:9] = 99 #assign sequence of values from 4 to 9 as 99\nprint(new_arr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A major diffence between lists and array is that, array slices are views on the original array. This means that\n# the data is not copied, and any modifications to the view will be reflected in the source\n#  array. \nmodi_arr = new_arr[4:9] \nmodi_arr[1] = 123456\nprint(new_arr)                  # you can see the changes are refelected in main array. \nmodi_arr[:]                  # the sliced variable      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# arrays can be treated like matrices\nmatrix_arr =np.array([[3,4,5],[6,7,8],[9,5,1]])\nprint(matrix_arr)\nprint(matrix_arr[1])\nprint(matrix_arr[0][2]) #first row and third column\nprint(matrix_arr[0,2]) # This is same as the above operation\n\n# from IPython.display import Image  # importing a image from my computer.\n# i = Image(filename='Capture.png')\n# i # Blue print of a matrix ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3d arrays -> this is a 2x2x3 array\nthree_d_arr = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\nprint(three_d_arr.shape)\nprint(\"returns the second list inside first list {}\".format(three_d_arr[0,1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"three_d_arr = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\nprint(three_d_arr[0])\n#if you omit later indices, the returned object will be a lowerdimensional\n# ndarray consisting of all the data along the higher dimensions\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"copied_values = three_d_arr[0].copy() # copy arr[0] value to copied_values\nthree_d_arr[0]= 99  # change all values of arr[0] to 99 \nprint(\"New value of three_d_arr: {}\".format(three_d_arr))  # check the new value of three_d_arr \nthree_d_arr[0] = copied_values # assign copied values back to three_d_arr[0]\nprint(\" three_d_arr again: {}\".format(three_d_arr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix_arr =np.array([[3,4,5],[6,7,8],[9,5,1]])\nprint(\"The original matrix {}:\".format(matrix_arr))\nprint(\"slices the first two rows:{}\".format(matrix_arr[:2])) # similar to list slicing. returns first two rows of the array\nprint(\"Slices the first two rows and two columns:{}\".format(matrix_arr[:2, 1:]))\nprint(\"returns 6 and 7: {}\".format(matrix_arr[1,:2]))\nprint(\"Returns first column: {}\".format(matrix_arr[:,:1])) #Note that a colon by itself means to take the entire axis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from IPython.display import Image  # importing a image from my computer.\n# j = Image(filename='Expre.png')\n# j # diagrammatic explanation of matrix array slicing works.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import random module from Numpy \npersonals = np.array(['Manu', 'Jeevan', 'Prakash', 'Manu', 'Prakash', 'Jeevan', 'Prakash'])\nprint(personals == 'Manu') #checks for the string 'Manu' in personals. If present it returns true; else false#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import random \nrandom_no = random.randn(7,4)\nprint(random_no)\nrandom_no[personals =='Manu'] #The function returns the rows for which the value of manu is true\n# Check the image displayed in the cell below. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from IPython.display import Image\n# k = Image(filename='Matrix.png')\n# k","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_no[personals == 'Manu', 2:] #First two columns and first two rows.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To select everything except 'Manu', you can != or negate the condition using -:\nprint(personals != 'Manu')\nrandom_no[~(personals == 'Manu')] #get everything except 1st and 4th rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# you can use boolean operator &(and), |(or)\nnew_variable = (personals == 'Manu') | (personals == 'Jeevan')\nprint(new_variable)\nrandom_no[new_variable] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_no[random_no < 0] =0 \nrandom_no # This will set all negative values to zero","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_no[ personals != 'Manu'] = 9 # This will set all rows except 1 and 4 to 9. \nrandom_no","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Fancy Indexing(Indexing using integer arrays)**\n> Fancy indexing copies data into a new array"},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import random\nalgebra = random.randn(7,4) # empty will return a matrix of size 7,4\nfor j in range(7):\n    algebra[j] = j\nalgebra","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To select a subset of rows in particular order, you can simply pass a list.\nalgebra[[4,5,1]] #returns a subset of rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fancy = np.arange(36).reshape(9,4) #reshape is to reshape an array\nprint(fancy)\nfancy[[1,4,3,2],[3,2,1,0]] #the position of the output array are[(1,3),(4,2),(3,1),(2,0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fancy[[1, 4, 8, 2]][:, [0, 3, 1, 2]] # entire first row is selected, but the elements are interchanged, same goes for 4th, 8th and 2 nd row.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# another way to do the above operation is by using np.ix_ function.\nfancy[np.ix_([1,4,8,2],[0,3,1,2])]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Transposing Arrays**"},{"metadata":{"trusted":true},"cell_type":"code","source":"transpose= np.arange(12).reshape(3,4) \ntranspose.T # the shape has changed to 4,3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#you can use np.dot function to perform matrix computations. You can calculate X transpose X as follows:\nnp.dot(transpose.T, transpose)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Universal functions**\n> They perform element wise operations on data in arrays."},{"metadata":{"trusted":true},"cell_type":"code","source":"funky =np.arange(8)\nprint(np.sqrt(funky))\nprint(np.exp(funky)) #exponent of the array\n# these are called as unary functions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Binary functions take two value, Others such as maximum, add\nx = random.randn(10)\ny = random.randn(10)\nprint(x)\nprint(y)\nprint(np.maximum(x,y))# element wise operation\nprint(np.modf(x))# function modf returns the fractional and integral parts of a floating point arrays","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of unary functions avaliable\nfrom IPython.display import Image  \nl = Image(filename='../input/unary.png')\nl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#List of binary functions available\nfrom IPython.display import Image  \nl = Image(filename='../input/binary.png')\nl\n#logical operators , and  greater, greater_equal,less, less_equal, equal, not_equal operations can also be performed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data processing using Arrays**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nmatrices =np.arange(-5,5,1)\nx, y = np.meshgrid(matrices, matrices) #mesh grid function takes two 1 d arrays and produces two 2d arrays\nprint(\"Default matrices: \", matrices)\nprint(\"Matrix values of y: {}\".format(y))\nprint(\"Matrix values of x: {}\".format(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1= np.array([1,2,3,4,5])\ny1 = np.array([6,7,8,9,10])\ncond =[True, False, True, True, False]\n#If you want to take a value from x1 whenever the corresponding value in cond is true, otherwise take value from y.\nz1 = [(x,y,z) for x,y,z in zip(x1, y1, cond)] # I have used zip function To illustrate the concept\nprint(z1)\nnp.where(cond, x1, y1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ra = np.random.randn(5,5)\n# If you want to replace negative values in ra with -1 and positive values with 1. You can do it using where function\nprint(ra)\nprint(np.where(ra>0, 1, -1)) # If values in ra are greater than zero, replace it with 1, else replace it with -1.\n# to set only positive values\nnp.where(ra >0, 1, ra) # same implies to negative values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Statistical methods**"},{"metadata":{"trusted":true},"cell_type":"code","source":"thie = np.random.randn(5,5)\nprint(thie)\nprint(thie.mean()) # calculates the mean of thie\nprint(np.mean(thie)) # alternate method to calculate mean\nprint(thie.sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jp =np.arange(12).reshape(4,3)\nprint(\"The arrays are: {}\".format(jp))\nprint(\"The sum of rows are :{}\".format(np.sum(jp, axis =0))) #axis =0, gives you sum of the columns. axis =1 , gives sum of rows.\n# remember this zero is for columns and one is for rows.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jp.sum(1)#returns sum of rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jp.cumsum(0)  #cumulative sum of columns, try the same for jp.cumprod(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jp.cumsum(1)#cumulative sum of rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xp =np.random.randn(100)\nprint((xp > 0).sum()) # sum of all positive values\nprint((xp < 0).sum())\ntandf =np.array([True,False,True,False,True,False])\nprint(tandf.any())#checks if any of the values are true\nprint(tandf.all()) #returns false even if a single value is false\n#These methods also work with non-boolean arrays, where non-zero elements evaluate to True.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Other array functions are:\n    * std, var -> standard deviation and variance\n    * min, max -> Minimum and Maximum\n    * argmin, argmax -> Indices of minimum and maximum elements"},{"metadata":{},"cell_type":"markdown","source":"## **Sorting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"lp = np.random.randn(8)\nprint(lp)\nlp.sort()\nlp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp = np.random.randn(4,4)\ntp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp.sort(1) #check the rows are sorted\ntp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"personals = np.array(['Manu', 'Jeevan', 'Prakash', 'Manu', 'Prakash', 'Jeevan', 'Prakash'])\nnp.unique(personals)# returns the unique elements in the array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(personals) # set is an alternative to unique function","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.in1d(personals, ['Manu']) #in1d function checks for the value 'Manu' and returns True, other wise returns False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Other Functions are :\n    * intersect1d(x, y)-> Compute the sorted, common elements in x and y\n    * union1d(x,y) -> compute the sorted union of elements\n    * setdiff1d(x,y) -> set difference, elements in x that are not in y\n    * setxor1d(x, y) -> Set symmetric differences; elements that are in either of the arrays, but not both"},{"metadata":{},"cell_type":"markdown","source":"## **Linear Algebra**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cp = np.array([[1,2,3],[4,5,6]])\ndp = np.array([[7,8],[9,10],[11,12]])\nprint(\"CP array :{}\".format(cp))\nprint(\"DP array :{}\".format(dp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# element wise multiplication\ncp.dot(dp) # this is equivalent to np.dot(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.dot(cp, np.ones(3)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# numpy.linalg has standard matrix operations like determinants and inverse.\nfrom numpy.linalg import inv, qr\ncp = np.array([[1,2,3],[4,5,6]])\nnew_mat = cp.T.dot(cp) # multiply cp inverse and cp, this is element wise multiplication\nprint(new_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sp = np.random.randn(5,5)\nprint(inv(sp))\nrt = inv(sp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to calculate the product of a matrix and its inverse\nsp.dot(rt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q,r = qr(sp)\nprint(q)\nr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Other Matrix Functions\n    * diag : Return the diagonal (or off-diagonal) elements of a square matrix as a 1D array, or convert a 1D array into a square\n    * matrix with zeros on the off-diagonal\n    * trace: Compute the sum of the diagonal elements\n    * det: Compute the matrix determinant\n    * eig: Compute the eigenvalues and eigenvectors of a square matrix\n    * pinv: Compute the pseudo-inverse of a square matrix\n    * svd: Compute the singular value decomposition (SVD)\n    * solve: Solve the linear system Ax = b for x, where A is a square matrix\n    * lstsq: Compute the least-squares solution to y = Xb"},{"metadata":{},"cell_type":"markdown","source":"<div>\n<a href=\"#\" style=\"font-size:48px;font-weight:600;margin-bottom:20px;\"> Scipy </a>\n<div style=\"padding-top: 20px;\"><p style=\"font-size:24px;\">Scipy library basics with code example</p></div>\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div>\n<a href=\"#\" style=\"font-size:48px;font-weight:600;margin-bottom:20px;\"> Pandas </a>\n<div style=\"padding-top: 20px;\"><p style=\"font-size:24px;\">Pandas library basics with code example</p></div>\n</div>\n\nPandas contains high level data structures and manipulation tools to make data analysis fast and easy in Python."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom pandas import Series, DataFrame # Series and Data Frame are two data structures available in pandas","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Series\nSeries is a one-dimensional array like object containing an array of data(any Numpy data type, and an associated array of data labels, called its index."},{"metadata":{"trusted":true},"cell_type":"code","source":"mjp= Series([5,4,3,2,1])# a simple series\nprint(mjp)       # A series is represented by index on the left and values on the right\nprint(mjp.values) # similar to dictionary. \".values\" command returns values in a series ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mjp.index.values) # returns the index values of the series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jeeva = Series([5,4,3,2,1,-7,-29], index =['a','b','c','d','e','f','h']) # The index is specified\nprint(jeeva) # try jeeva.index and jeeva.values\nprint(jeeva['a']) # selecting a particular value from a Series, by using index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jeeva['d'] = 9 # change the value of a particular element in series\nprint(jeeva)\njeeva[['a','b','c']] # select a group of values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(jeeva[jeeva>0]) # returns only the positive values\nprint(jeeva *2) # multiplies 2 to each element of a series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nnp.mean(jeeva) # you can apply numpy functions to a Series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('b' in jeeva) # checks whether the index is present in Series or not\nprint('z' in jeeva)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"player_salary ={'Rooney': 50000, 'Messi': 75000, 'Ronaldo': 85000, 'Fabregas':40000, 'Van persie': 67000} \nnew_player = Series(player_salary)# converting a dictionary to a series\nprint(new_player) # the series has keys of a dictionary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"players =['Klose', 'Messi', 'Ronaldo', 'Van persie', 'Ballack'] \nplayer_1 =Series(player_salary, index= players)\nprint(player_1) # I have changed the index of the Series. Since, no value was not found for Klose and Ballack, it appears as NAN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isnull(player_1)#checks for Null values in player_1, pd denotes a pandas dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.notnull(player_1)# Checks for null values that are not Null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"player_1.name ='Bundesliga players' # name for the Series\nplayer_1.index.name='Player names' #name of the index\nplayer_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"player_1.index =['Neymar', 'Hulk', 'Pirlo', 'Buffon', 'Anderson'] # is used to alter the index of Series\nplayer_1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Frame\nData frame is a spread sheet like structure, containing ordered collection of columns. Each column can have different value type. Data frame has both row index and column index."},{"metadata":{"trusted":true},"cell_type":"code","source":"states ={'State' :['Gujarat', 'Tamil Nadu', ' Andhra', 'Karnataka', 'Kerala'],\n                  'Population': [36, 44, 67,89,34],\n                  'Language' :['Gujarati', 'Tamil', 'Telugu', 'Kannada', 'Malayalam']}\nindia = DataFrame(states) # creating a data frame\nindia","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DataFrame(states, columns=['State', 'Language', 'Population']) # change the sequence of column index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_frame = DataFrame(states, columns=['State', 'Language', 'Population', 'Per Capita Income'], index =['a','b','c','d','e'])\nnew_frame\n#if you pass a column that isnt in states, it will appear with Na values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(new_farme.columns)\nprint(new_farme['State']) # retrieveing data like dictionary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_farme.Population # like Series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_farme.ix[3] # rows can be retrieved using .ic function\n# here I have retrieved 3rd row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" new_farme","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_farme['Per Capita Income'] = 99 # the empty per capita income column can be assigned a value\nnew_farme","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_farme['Per Capita Income'] = np.arange(5) # assigning a value to the last column\nnew_farme","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series = Series([44,33,22], index =['b','c','d'])\nnew_farme['Per Capita Income'] = series\n#when assigning list or arrays to a column, the values length should match the length of the DataFrame\nnew_farme # again the missing values are displayed as NAN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_farme['Development'] = new_farme.State == 'Gujarat'# assigning a new column\nprint(new_farme)\ndel new_farme['Development'] # will delete the column 'Development'\nnew_farme","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data ={'Modi': {2010: 72, 2012: 78, 2014 : 98},'Rahul': {2010: 55, 2012: 34, 2014: 22}}\nelections = DataFrame(new_data) \nprint(elections) # the outer dict keys are columns and inner dict keys are rows\nelections.T # transpose of a data frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DataFrame(new_data, index =[2012, 2014, 2016]) # you can assign index for the data frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ex= {'Gujarat':elections['Modi'][:-1], 'India': elections['Rahul'][:2]}\npx =DataFrame(ex)\npx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.index.name = 'year'\npx.columns.name = 'politicians'\npx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jeeva = Series([5,4,3,2,1,-7,-29], index =['a','b','c','d','e','f','h'])\nindex = jeeva.index\nprint(index) #u denotes unicode\nprint(index[1:]) # returns all the index elements except a. \nindex[1] = 'f' # you cannot modify an index element. It will generate an error. In other words, they are immutable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(px)\n2013 in px.index # checks if 2003 is an index in data frame px","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reindex"},{"metadata":{"trusted":true},"cell_type":"code","source":"var = Series(['Python', 'Java', 'c', 'c++', 'Php'], index =[5,4,3,2,1])\nprint(var)\nvar1 = var.reindex([1,2,3,4,5])# reindex creates a new object \nprint(var1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var.reindex([1,2,3,4,5,6,7])# introduces new indexes with values Nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var.reindex([1,2,3,4,5,6,7], fill_value =1) # you can use fill value to fill the Nan values. Here I have used fill value as 1. You can use any value.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gh =Series(['Dhoni', 'Sachin', 'Kohli'], index =[0,2,4])\nprint(gh)\ngh.reindex(range(6), method ='ffill') #ffill is forward fill. It forward fills the values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gh.reindex(range(6), method ='bfill')# bfill, backward fills the values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfp = DataFrame(np.arange(9).reshape((3,3)),index =['a','b','c'], columns =['Gujarat','Tamil Nadu', 'Kerala'])\nfp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fp1 =fp.reindex(['a', 'b', 'c', 'd'], columns = states) # reindexing columns and indices\nfp1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Other Reindexing arguments\n    **limit** When forward- or backfilling, maximum size gap to fill\n    **level** Match simple Index on level of MultiIndex, otherwise select subset of\n    **copy** Do not copy underlying data if new index is equivalent to old index. True by default (i.e. always copy data)."},{"metadata":{},"cell_type":"markdown","source":"## Dropping entries from an axis"},{"metadata":{"trusted":true},"cell_type":"code","source":"er = Series(np.arange(5), index =['a','b','c','d','e'])\nprint(er)\ner.drop(['a','b']) #drop method will return a new object  with values deleted from an axis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"states ={'State' :['Gujarat', 'Tamil Nadu', ' Andhra', 'Karnataka', 'Kerala'],\n                  'Population': [36, 44, 67,89,34],\n                  'Language' :['Gujarati', 'Tamil', 'Telugu', 'Kannada', 'Malayalam']}\nindia = DataFrame(states, columns =['State', 'Population', 'Language'])\nprint(india)\nindia.drop([0,1])# will drop index 0 and 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"india.drop(['State', 'Population'], axis =1 )# the function dropped population and state columns. Apply the same concept with axis =0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selection, Indexing and Filtering"},{"metadata":{"trusted":true},"cell_type":"code","source":"var = Series(['Python', 'Java', 'c', 'c++', 'Php'], index =[5,4,3,2,1])\nvar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (var[5])\nprint (var[2:4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var[[3,2,1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var[var == 'Php']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"states ={'State' :['Gujarat', 'Tamil Nadu', ' Andhra', 'Karnataka', 'Kerala'],\n                  'Population': [36, 44, 67,89,34],\n                  'Language' :['Gujarati', 'Tamil', 'Telugu', 'Kannada', 'Malayalam']}\nindia = DataFrame(states, columns =['State', 'Population', 'Language'])\nindia","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"india[['Population', 'Language']] # retrieve data from data frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"india[india['Population'] > 50] # returns data for population greater than 50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"india[:3] # first three rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for selecting specific rows and columns, you can use ix function\nimport pandas as pd\nstates ={'State' :['Gujarat', 'Tamil Nadu', ' Andhra', 'Karnataka', 'Kerala'],\n                  'Population': [36, 44, 67,89,34],\n                  'Language' :['Gujarati', 'Tamil', 'Telugu', 'Kannada', 'Malayalam']}\nindia = DataFrame(states, columns =['State', 'Population', 'Language'], index =['a', 'b', 'c', 'd', 'e'])\nindia","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"india.ix[['a','b'], ['State','Language']] # this is how you select subset of rows","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Numpy cheat sheet\n\nImport numpy as np\n\n#### Importing/exporting\n* np.loadtxt('file.txt') | From a text file\n* np.genfromtxt('file.csv',delimiter=',') | From a CSV file\n* np.savetxt('file.txt',arr,delimiter=' ') | Writes to a text file\n* np.savetxt('file.csv',arr,delimiter=',') | Writes to a CSV file\n\n#### Creating Arrays\n* np.array([1,2,3]) | One dimensional array\n* np.array([(1,2,3),(4,5,6)]) | Two dimensional array\n* np.zeros(3) | 1D array of length 3 all values 0\n* np.ones((3,4)) | 3x4 array with all values 1\n* np.eye(5) | 5x5 array of 0 with 1 on diagonal (Identity matrix)\n* np.linspace(0,100,6) | Array of 6 evenly divided values from 0 to 100\n* np.arange(0,10,3) | Array of values from 0 to less than 10 with step 3 (eg [0,3,6,9])\n* np.full((2,3),8) | 2x3 array with all values 8\n* np.random.rand(4,5) | 4x5 array of random floats between 0–1\n* np.random.rand(6,7)*100 | 6x7 array of random floats between 0–100\n* np.random.randint(5,size=(2,3)) | 2x3 array with random ints between 0–4\n\n#### Inspecting Properties\n* arr.size | Returns number of elements in arr\n* arr.shape | Returns dimensions of arr (rows,columns)\n* arr.dtype | Returns type of elements in arr\n* arr.astype(dtype) | Convert arr elements to type dtype\n* arr.tolist() | Convert arr to a Python list\n* np.info(np.eye) | View documentation for np.eye\n\n#### Copying/sorting/reshaping\n* np.copy(arr) | Copies arr to new memory\n* arr.view(dtype) | Creates view of arr elements with type dtype\n* arr.sort() | Sorts arr\n* arr.sort(axis=0) | Sorts specific axis of arr\n* two_d_arr.flatten() | Flattens 2D array two_d_arr to 1D\n* arr.T | Transposes arr (rows become columns and vice versa)\n* arr.reshape(3,4) | Reshapes arr to 3 rows, 4 columns without changing data\n* arr.resize((5,6)) | Changes arr shape to 5x6 and fills new values with 0\n\n#### Adding/removing Elements\n* np.append(arr,values) | Appends values to end of arr\n* np.insert(arr,2,values) | Inserts values into arr before index 2\n* np.delete(arr,3,axis=0) | Deletes row on index 3 of arr\n* np.delete(arr,4,axis=1) | Deletes column on index 4 of arr\n\n#### Combining/splitting\n* np.concatenate((arr1,arr2),axis=0) | Adds arr2 as rows to the end of arr1\n* np.concatenate((arr1,arr2),axis=1) | Adds arr2 as columns to end of arr1\n* np.split(arr,3) | Splits arr into 3 sub-arrays\n* np.hsplit(arr,5) | Splits arr horizontally on the 5th index\n\n#### Indexing/slicing/subsetting\n* arr[5] | Returns the element at index 5\n* arr[2,5] | Returns the 2D array element on index [2][5]\n* arr[1]=4 | Assigns array element on index 1 the value 4\n* arr[1,3]=10 | Assigns array element on index [1][3] the value 10\n* arr[0:3] | Returns the elements at indices 0,1,2 (On a 2D array: returns rows 0,1,2)\n* arr[0:3,4] | Returns the elements on rows 0,1,2 at column 4\n* arr[:2] | Returns the elements at indices 0,1 (On a 2D array: returns rows 0,1)\n* arr[:,1] | Returns the elements at index 1 on all rows\n* arr<5 | Returns an array with boolean values\n* (arr1<3) & (arr2>5) | Returns an array with boolean values\n* ~arr | Inverts a boolean array\n* arr[arr<5] | Returns array elements smaller than 5\n\n#### Scalar Math\n* np.add(arr,1) | Add 1 to each array element\n* np.subtract(arr,2) | Subtract 2 from each array element\n* np.multiply(arr,3) | Multiply each array element by 3\n* np.divide(arr,4) | Divide each array element by 4 (returns np.nan for division by zero)\n* np.power(arr,5) | Raise each array element to the 5th power\n\n#### Vector Math\n* np.add(arr1,arr2) | Elementwise add arr2 to arr1\n* np.subtract(arr1,arr2) | Elementwise subtract arr2 from arr1\n* np.multiply(arr1,arr2) | Elementwise multiply arr1 by arr2\n* np.divide(arr1,arr2) | Elementwise divide arr1 by arr2\n* np.power(arr1,arr2) | Elementwise raise arr1 raised to the power of arr2\n* np.array_equal(arr1,arr2) | Returns True if the arrays have the same elements and shape\n* np.sqrt(arr) | Square root of each element in the array\n* np.sin(arr) | Sine of each element in the array\n* np.log(arr) | Natural log of each element in the array\n* np.abs(arr) | Absolute value of each element in the array\n* np.ceil(arr) | Rounds up to the nearest int\n* np.floor(arr) | Rounds down to the nearest int\n* np.round(arr) | Rounds to the nearest int\n\n#### Statistics\n* np.mean(arr,axis=0) | Returns mean along specific axis\n* arr.sum() | Returns sum of arr\n* arr.min() | Returns minimum value of arr\n* arr.max(axis=0) | Returns maximum value of specific axis\n* np.var(arr) | Returns the variance of array\n* np.std(arr,axis=1) | Returns the standard deviation of specific axis\n* arr.corrcoef() | Returns correlation coefficient of array"},{"metadata":{},"cell_type":"markdown","source":"## Pandas Cheatsheet\n\nimport pandas as pd\nimport numpy as np\n\n#### Importing Data\n* pd.read_csv(filename) | From a CSV file\n* pd.read_table(filename) | From a delimited text file (like TSV)\n* pd.read_excel(filename) | From an Excel file\n* pd.read_sql(query, connection_object) | Read from a SQL table/database\n* pd.read_json(json_string) | Read from a JSON formatted string, URL or file.\n* pd.read_html(url) | Parses an html URL, string or file and extracts tables to a list of dataframes\n* pd.read_clipboard() | Takes the contents of your clipboard and passes it to read_table()\n* pd.DataFrame(dict) | From a dict, keys for columns names, values for data as lists\n\n#### Exporting Data\n* df.to_csv(filename) | Write to a CSV file\n* df.to_excel(filename) | Write to an Excel file\n* df.to_sql(table_name, connection_object) | Write to a SQL table\n* df.to_json(filename) | Write to a file in JSON format\n\n#### Create Test Objects\nUseful for testing code segements\n\n* pd.DataFrame(np.random.rand(20,5)) | 5 columns and 20 rows of random floats\n* pd.Series(my_list) | Create a series from an iterable my_list\n* df.index = pd.date_range('1900/1/30', periods=df.shape[0]) | Add a date index\n\n#### Viewing/Inspecting Data\n* df.head(n) | First n rows of the DataFrame\n* df.tail(n) | Last n rows of the DataFrame\n* df.shape | Number of rows and columns\n* df.info() | Index, Datatype and Memory information\n* df.describe() | Summary statistics for numerical columns\n* s.value_counts(dropna=False) | View unique values and counts\n* df.apply(pd.Series.value_counts) | Unique values and counts for all columns\n\n#### Selection\n* df[col] | Returns column with label col as Series\n* df[[col1, col2]] | Returns columns as a new DataFrame\n* s.iloc[0] | Selection by position\n* s.loc['index_one'] | Selection by index\n* df.iloc[0,:] | First row\n* df.iloc[0,0] | First element of first column\n\n#### Data Cleaning\n* df.columns = ['a','b','c'] | Rename columns\n* pd.isnull() | Checks for null Values, Returns Boolean Arrray\n* pd.notnull() | Opposite of pd.isnull()\n* df.dropna() | Drop all rows that contain null values\n* df.dropna(axis=1) | Drop all columns that contain null values\n* df.dropna(axis=1,thresh=n) | Drop all rows have have less than n non null values\n* df.fillna(x) | Replace all null values with x\n* s.fillna(s.mean()) | Replace all null values with the mean (mean can be replaced with almost any function from the statistics module)\n* s.astype(float) | Convert the datatype of the series to float\n* s.replace(1,'one') | Replace all values equal to 1 with 'one'\n* s.replace([1,3],['one','three']) | Replace all 1 with 'one' and 3 with 'three'\n* df.rename(columns=lambda x: x + 1) | Mass renaming of columns\n* df.rename(columns={'old_name': 'new_ name'}) | Selective renaming\n* df.set_index('column_one') | Change the index\n* df.rename(index=lambda x: x + 1) | Mass renaming of index\n\n#### Filter, Sort, and Groupby\n* df[df[col] > 0.5] | Rows where the column col is greater than 0.5\n* df[(df[col] > 0.5) & (df[col] < 0.7)] | Rows where 0.7 > col > 0.5\n* df.sort_values(col1) | Sort values by col1 in ascending order\n* df.sort_values(col2,ascending=False) | Sort values by col2 in descending order\n* df.sort_values([col1,col2],ascending=[True,False]) | Sort values by col1 in ascending order then col2 in descending order\n* df.groupby(col) | Returns a groupby object for values from one column\n* df.groupby([col1,col2]) | Returns groupby object for values from multiple columns\n* df.groupby(col1)[col2] | Returns the mean of the values in col2, grouped by the values in col1 (mean can be replaced with almost any function from the statistics module)\n* df.pivot_table(index=col1,values=[col2,col3],aggfunc=mean) | Create a pivot table that groups by col1 and calculates the mean of col2 and col3\n* df.groupby(col1).agg(np.mean) | Find the average across all columns for every unique col1 group\n* df.apply(np.mean) | Apply the function np.mean() across each column\n* nf.apply(np.max,axis=1) | Apply the function np.max() across each row\n\n#### Join/Combine\n* df1.append(df2) | Add the rows in df1 to the end of df2 (columns should be identical)\n* pd.concat([df1, df2],axis=1) | Add the columns in df1 to the end of df2 (rows should be identical)\n* df1.join(df2,on=col1,how='inner') | SQL-style join the columns in df1 with the columns on df2 where the rows for\n* col have identical values. 'how' can be one of 'left', 'right', 'outer', 'inner'\n\n#### Statistics\nThese can all be applied to a series as well.\n* df.describe() | Summary statistics for numerical columns\n* df.mean() | Returns the mean of all columns\n* df.corr() | Returns the correlation between columns in a DataFrame\n* df.count() | Returns the number of non-null values in each DataFrame column\n* df.max() | Returns the highest value in each column\n* df.min() | Returns the lowest value in each column\n* df.median() | Returns the median of each column\n* df.std() | Returns the standard deviation of each column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Numpy\n# import numpy as np\n# a = np.arange(9) \n# a = a.reshape(3,3)\n# size = a.size\n# shape = a.shape\n# for x in np.nditer(a, order='C'):\n#     print(x, end=',')\n# for i in range(a.shape[0]):\n#     for j in range(a.shape[1]):\n#         print(a[i][j], end=',')\n# x = np.zeros((3, 5, 2), dtype=np.int)\n# d3_shape = x.shape\n# y = np.zeros((3,5), dtype=np.int)\n# d2_shape = y.shape\n# a = np.array([[0, 1, 4],[3, 4, 5],[6, 7, 8]])\n# Diagonal difference problem hakerrank \n# l_d = 0\n# r_d = 0\n# for i in range(a.shape[0]):\n#     for j in range(a.shape[1]):\n#         if i == j:\n#             l_d += a[i][j]\n#         if j == (a.shape[1] - i-1):\n#             r_d += a[i][j]\n# output = abs(l_d-r_d)\n# print(output)\n# List comprehension\n# b = [20, 25, 30, 14]\n# b_list = [i for i in b if (i % 2 == 0 and i % 5 == 0)]\n# b_list\n# c = [[0, 1, 4],[3, 4, 5],[6, 7, 8]]\n# len(c[0])\n# ans = 0\n# for i in range(len(c)):\n#     ans += c[i][i]\n#     ans -= c[i][len(c)-1-i]\n    \n# ans","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Special Thanks and acknowledgement to \n    * https://nbviewer.jupyter.org/gist/manujeevanprakash/\n    * https://www.dataquest.io/blog/numpy-cheat-sheet/\n    * https://www.dataquest.io/blog/pandas-cheat-sheet/"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}